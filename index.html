<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Erfaneh Mahmoudzadeh - Portfolio</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body>

    <header class="header">
        <div class="container">
            <div class="profile-info">
                <h1>Erfaneh Mahmoudzadeh</h1>
                <p>Highly motivated M.Sc. in Computing Science with expertise in Machine Learning, Deep Learning, and Generative AI, seeking to leverage extensive research and practical experience to solve complex data challenges.</p>
            </div>
            <div class="contact-info">
                <p><i class="fa fa-envelope"></i> <a href="mailto:er.mahmoudzadeh@gmail.com">er.mahmoudzadeh@gmail.com</a></p>
                <p><i class="fa fa-linkedin"></i> <a href="https://www.linkedin.com/in/erfaneh-mahmoudzadeh/">erfaneh-mahmoudzadeh</a></p>
                <p><i class="fa fa-github"></i> <a href="https://github.com/erfmah">erfmah</a></p>
                <p><i class="fa fa-map-marker"></i> BC, Canada</p>
            </div>
        </div>
    </header>

    <main class="main-content container">

        <section id="skills" class="section">
            <h2>Skills</h2>
            <div class="skills-list">
                <div class="skill-category">
                    <h3>Languages</h3>
                    <p>Python, C++, Java, SQL, R, Matlab</p>
                </div>
                <div class="skill-category">
                    <h3>Technical Skills</h3>
                    <p>Data Science, Machine Learning, Deep Learning, Transformers, Graph Neural Networks (GNNs), Generative AI, LLM, Database, NLP</p>
                </div>
                <div class="skill-category">
                    <h3>Frameworks/Libraries</h3>
                    <p>Pytorch, TensorFlow, Numpy, scikit-learn, SciPy, DGL, Pandas, Matplotlib, Hugging Face</p>
                </div>
                <div class="skill-category">
                    <h3>Developer Tools</h3>
                    <p>Git, Docker, Excel, AWS</p>
                </div>
            </div>
        </section>
        
        <section id="education" class="section">
            <h2>Education</h2>
            <div class="experience-item">
                <h3>M.Sc. in Computing Science</h3>
                <p class="company-date">Simon Fraser University (SFU) | <span class="location">Burnaby, Canada</span> | <span class="date">Sept. 2021 - Aug. 2024</span></p>
                <ul>
                    <li>GPA: 3.9/4.0</li>
                    <li>Thesis: Deep Generative Models for Subgraph Prediction - Best thesis award nominee</li>
                </ul>
            </div>
            <div class="experience-item">
                <h3>B.Sc. in Software Engineering</h3>
                <p class="company-date">Shahid Beheshti University (SBU) | <span class="location">Tehran, Iran</span> | <span class="date">Sept. 2015 - Feb. 2020</span></p>
                <ul>
                    <li>GPA: 3.9/4.0</li>
                    <li>Thesis: Forecasting Macroeconomic Variables Using Firm-Level Data - Best thesis award</li>
                </ul>
            </div>
        </section>

        <section id="publications" class="section">
            <h2>Research & Publications</h2>
            <div class="publication-item">
                <h3><a href="https://dl.acm.org/doi/10.1145/3583780.3614941">Joint Link Prediction Via Inference from a Model</a> - CIKM 2023</h3>
                <p class="publication-details">
                    <a href="https://github.com/parmisnaddaf/Joint-Link-Prediction"><i class="fa fa-github"></i> GitHub Repository</a>
                </p>
                <p class="abstract">A Joint Link Prediction Query (JLPQ) specifies a set of links to be predicted, given another set of links as well as node attributes as evidence. While single link prediction has been well studied in literature on deep graph learning, predicting multiple links together has gained little attention. This paper presents a novel framework for computing JLPQs using a probabilistic deep Graph Generative Model. Specifically, we develop inference procedures for an inductively trained Variational Graph Auto-Encoder (VGAE) that estimates the joint link probability for any input JLPQ, without retraining. For evaluation, we apply inference to a range of joint link prediction queries on six benchmark datasets. We find that for most datasets and query types, joint link prediction via inference from a model achieves good predictive performance, better than the independent link prediction baselines (by 0.02-0.4 AUC points depending on the dataset).</p>
            </div>
            <div class="publication-item">
                <h3><a href="https://ebooks.iospress.nl/volumearticle/69951">Deep Generative Models for Subgraph Prediction</a> - ECAI 2024</h3>
                <p class="publication-details">
                    <a href="https://github.com/erfmah/Answering_Graph_Queries"><i class="fa fa-github"></i> GitHub Repository</a>
                </p>
                <p class="abstract">Graph Neural Networks (GNNs) are important across different domains, such as social network analysis and recommendation systems, due to their ability to model complex relational data. This paper introduces subgraph queries as a new task for deep graph learning. Unlike traditional graph prediction tasks that focus on individual components like link prediction or node classification, subgraph queries jointly predict the components of a target subgraph based on evidence that is represented by an observed subgraph. For instance, a subgraph query can predict a set of target links and/or node labels. To answer subgraph queries, we utilize a probabilistic deep Graph Generative Model. Specifically, we inductively train a Variational Graph Auto-Encoder (VGAE) model, augmented to represent a joint distribution over links, node features and labels. Bayesian optimization is used to tune a weighting for the relative importance of links, node features and labels in a specific domain. We describe a deterministic and a sampling-based inference method for estimating subgraph probabilities from the VGAE generative graph distribution, without retraining, in zero-shot fashion. For evaluation, we apply the inference methods on a range of subgraph queries on six benchmark datasets. We find that inference from a model achieves superior predictive performance, surpassing independent prediction baselines with improvements in AUC scores ranging from 0.06 to 0.2 points, depending on the dataset.</p>
            </div>
            <div class="publication-item">
                <h3>Enhancing Graph Generation With First-Order Logic Rules - IJCAI/TKR 2025</h3>
                <p class="abstract">Existing graph generative models produce graphs that are often quite realistic, but sometimes miss domain-specific patterns. Enhancing graph learning with domain knowledge is one of the current frontiers for neural models of graph data. In this paper, we propose a new approach to enhancing deep graph generative models with knowledge that is represented by first-order logic rules. First-order logic provides an expressive formalism for representing interpretable causal knowledge about relational structures. Our conceptual contribution is a new first-order semantic loss function for training a graph generative model on relational data: maximize the model likelihood subject to a rule moment matching constraint, namely that the expected instance count of each rule matches its observed instance count. Our algorithmic contribution is a novel method for computing the expected instance count of a first-order rule for a Variational Graph Autoencoder model, based on matrix multiplication. Empirical evaluation on five benchmark datasets, both homogeneous and heterogeneous, shows that rule moment matching improves the quality of generated graphs substantially (by orders of magnitude on standard graph quality metrics), and improves predictive accuracy on the downstream task of node classification.</p>
            </div>
        </section>

        <section id="projects" class="section">
            <h2>Projects</h2>
            <div class="experience-item">
                <h3>Graph-based Anomaly Detection with Transformers</h3>
                <p class="company-date">Research Assistant at SFU | <span class="date">Oct. 2024 - Dec. 2024</span></p>
                <ul>
                    <li>Developed a deep learning architecture combining Graph Attention Networks and Transformers for detecting structural anomalies in Reddit social network data.</li>
                </ul>
            </div>
            <div class="experience-item">
                <h3>Graph Neural Network-Based Cancer Diagnosis</h3>
                <p class="company-date">Research Assistant at SFU | <span class="date">Aug. 2024 - Oct. 2024</span></p>
                <ul>
                    <li>Developed, trained, a GNN based model to generate synthetic medical images for a better performance on trainging image detection models.</li>
                </ul>
            </div>
            <div class="experience-item">
                <h3>Transformers for Handwritten Digit Recognition</h3>
                <p class="company-date">Research Assistant at SBU | <span class="date">Jan. 2020 - Jun. 2020</span></p>
                <ul>
                    <li>Developed a handwritten digit detection model using Transformer Networks and BERT on the NIST SD19 dataset.</li>
                </ul>
            </div>
            <div class="experience-item">
                <h3>Forecasting Macroeconomic Variables Using Firm-Level Data</h3>
                <p class="company-date">Thesis at SBU | <span class="date">Sept. 2019 - Feb. 2020</span></p>
                <ul>
                    <li>Developed a GDP forecasting model employing data analysis, feature reduction, and advanced ML methods.</li>
                    <li>Successfully devised and evaluated six distinct prediction models. Demonstrated expertise in data-driven insights, model evaluation, and forecasting methodologies.</li>
                </ul>
            </div>
        </section>

        <section id="experience" class="section">
            <h2>Work Experience</h2>
            <div class="experience-item">
                <h3>Data Scientist Intern</h3>
                <p class="company-date">Visier | <span class="location">Burnaby, Canada</span> | <span class="date">Jan. 2025 - Present</span></p>
                <ul>
                    <li>Developed advanced data analysis on large-scale, multi-dimensional HR datasets using AWS infrastructure to create comprehensive reports on industry trends.</li>
                    <li>Optimized predictive model performance through hyperparameter tuning, significantly improving the AUC by 0.1 and Uplift by 1.1 and preventing overfitting of employee resignation rate predictions.</li>
                    <li>Pioneered a specialized LLM agent utilizing AWS Databricks, Model Context Protocol (MCP) and Retrieval-Augmented Generation (RAG) to provide secure, accurate responses to security questions for internal and external clients.</li>
                </ul>
            </div>
            <div class="experience-item">
                <h3>Data Scientist Intern</h3>
                <p class="company-date">Zen Artech Services | <span class="date">Jul. 2022 - Oct. 2022</span></p>
                <ul>
                    <li>Developed a recommendation system using link prediction algorithms to improve both the accuracy and AUC.</li>
                    <li>Collaborated with teams to ensure seamless integration. Optimized performance, resulting in an up to 4% improvement in AUC on Amazon dataset.</li>
                </ul>
            </div>
            <div class="experience-item">
                <h3>Database Engineer Intern</h3>
                <p class="company-date">Tosan Intelligent Data Miners | <span class="date">Jul. 2018 - Sept. 2018</span></p>
                <ul>
                    <li>Developed and implemented a Regex solution to automate response data analysis, streamlining report classification process and saving the team an average of 10 hours per month</li>
                    <li>Engineered and implemented innovative data validity verification algorithms, leading to a 5% enhancement in response time for identifying relationships among loan applicants</li>
                </ul>
            </div>
        </section>

        <section id="awards" class="section">
            <h2>Awards & Honors</h2>
            <ul>
                <li>Best Poster Award at Huawei Joint Lab Annual Workshop (Nov. 2024)</li>
                <li>Best Master's Thesis Award Nominee (July 2024)</li>
                <li>Upper Bound talent Bursary at Amii (Apr. 2024)</li>
                <li>Honored to be the best faculty thesis (Feb. 2020)</li>
            </ul>
        </section>
        
    </main>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Erfaneh Mahmoudzadeh. All rights reserved.</p>
        </div>
    </footer>

</body>
</html>
